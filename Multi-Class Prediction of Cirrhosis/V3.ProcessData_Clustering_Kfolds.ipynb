{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1d68e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jarod\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization, Normalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import log_loss\n",
    "from skmultilearn.model_selection import IterativeStratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8439c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21532</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2574</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>19237</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3428</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>13727</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2576</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>18460</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>71.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>16658</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.1</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>96.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>1166</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>16839</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>224.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>1492</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>17031</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>142.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>1576</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>25873</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>S</td>\n",
       "      <td>2.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>51.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>62.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>3584</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>22960</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.7</td>\n",
       "      <td>248.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>57.35</td>\n",
       "      <td>118.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>1978</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>19237</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.7</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>22.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>74.40</td>\n",
       "      <td>85.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7905 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n",
       "id                                                                            \n",
       "0        999  D-penicillamine  21532   M       N            N       N     N   \n",
       "1       2574          Placebo  19237   F       N            N       N     N   \n",
       "2       3428          Placebo  13727   F       N            Y       Y     Y   \n",
       "3       2576          Placebo  18460   F       N            N       N     N   \n",
       "4        788          Placebo  16658   F       N            Y       N     N   \n",
       "...      ...              ...    ...  ..     ...          ...     ...   ...   \n",
       "7900    1166  D-penicillamine  16839   F       N            N       N     N   \n",
       "7901    1492          Placebo  17031   F       N            Y       N     N   \n",
       "7902    1576  D-penicillamine  25873   F       N            N       Y     S   \n",
       "7903    3584  D-penicillamine  22960   M       N            Y       N     N   \n",
       "7904    1978  D-penicillamine  19237   F       N            N       N     N   \n",
       "\n",
       "      Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "id                                                                \n",
       "0           2.3        316.0     3.35   172.0    1601.0  179.80   \n",
       "1           0.9        364.0     3.54    63.0    1440.0  134.85   \n",
       "2           3.3        299.0     3.55   131.0    1029.0  119.35   \n",
       "3           0.6        256.0     3.50    58.0    1653.0   71.30   \n",
       "4           1.1        346.0     3.65    63.0    1181.0  125.55   \n",
       "...         ...          ...      ...     ...       ...     ...   \n",
       "7900        0.8        309.0     3.56    38.0    1629.0   79.05   \n",
       "7901        0.9        260.0     3.43    62.0    1440.0  142.00   \n",
       "7902        2.0        225.0     3.19    51.0     933.0   69.75   \n",
       "7903        0.7        248.0     2.75    32.0    1003.0   57.35   \n",
       "7904        0.7        256.0     3.23    22.0     645.0   74.40   \n",
       "\n",
       "      Tryglicerides  Platelets  Prothrombin  Stage Status  \n",
       "id                                                         \n",
       "0              63.0      394.0          9.7    3.0      D  \n",
       "1              88.0      361.0         11.0    3.0      C  \n",
       "2              50.0      199.0         11.7    4.0      D  \n",
       "3              96.0      269.0         10.7    3.0      C  \n",
       "4              96.0      298.0         10.6    4.0      C  \n",
       "...             ...        ...          ...    ...    ...  \n",
       "7900          224.0      344.0          9.9    2.0      C  \n",
       "7901           78.0      277.0         10.0    4.0      C  \n",
       "7902           62.0      200.0         12.7    2.0      D  \n",
       "7903          118.0      221.0         10.6    4.0      D  \n",
       "7904           85.0      336.0         10.3    3.0      C  \n",
       "\n",
       "[7905 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col='id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29fa0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en variables dependientes y independientes\n",
    "X = df.drop('Status', axis=1)\n",
    "y = df['Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5dacff",
   "metadata": {},
   "source": [
    "### Algunas ingenieria de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a0730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Age_Format (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    # Iteramos por el nombre de columna de Age, calculando el valor real edad desde los dias de nacimiento de cada paciente.\n",
    "    def transform(self,X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        new_age = []\n",
    "        for i in X_copy['Age']:\n",
    "            days = i\n",
    "            age = days/365\n",
    "            new_age.append(round(age))\n",
    "        \n",
    "        X_copy = X_copy.drop('Age', axis = 1)\n",
    "        X_copy['Age'] = new_age\n",
    "        \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3aab74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_ = Age_Format()\n",
    "X = Age_.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fbf1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sgot_Range (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    # Iteramos por el nombre de columna de Sgot, calculando en base a analisis, los pacientes con mayor o menor\n",
    "    # rango. Si supera el nivel 100, se marcara como 1, en caso contrario 0\n",
    "    def transform(self,X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        Sgot_survival = []\n",
    "        for i in X_copy['SGOT']:\n",
    "            if i > 100:\n",
    "                Sgot_survival.append(1)\n",
    "            else: Sgot_survival.append(0)\n",
    "        \n",
    "        X_copy['Sgot_survival'] = Sgot_survival\n",
    "        \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46699dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sgot_ =  Sgot_Range()\n",
    "X = Sgot_.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34351de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bilirubin_Range (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    # Iteramos por el nombre de columna de Bilirubin, calculando en base a analisis, los pacientes con mayor o menor\n",
    "    # rango. Si supera el nivel 3, se marcara como 1, en caso contrario 0\n",
    "    def transform(self,X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        Bilirubin_survival = []\n",
    "        for i in X_copy['Bilirubin']:\n",
    "            if i > 1.5:\n",
    "                Bilirubin_survival.append(1)\n",
    "            else: Bilirubin_survival.append(0)\n",
    "        \n",
    "        X_copy['Bilirubin_survival'] = Bilirubin_survival\n",
    "        \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4366d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bilirubin_ = Bilirubin_Range()\n",
    "X = Bilirubin_.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9e2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Copper_Range (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    # Iteramos por el nombre de columna de Copper, calculando en base a analisis, los pacientes con mayor o menor\n",
    "    # rango. Si supera el nivel 60, se marcara como 1, en caso contrario 0\n",
    "    def transform(self,X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        Copper_survival = []\n",
    "        for i in X_copy['Copper']:\n",
    "            if i >= 60:\n",
    "                Copper_survival.append(1)\n",
    "            else: Copper_survival.append(0)\n",
    "        \n",
    "        X_copy['Copper_survival'] = Copper_survival\n",
    "        \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a73c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Copper_ = Copper_Range()\n",
    "X = Copper_.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d0b0d",
   "metadata": {},
   "source": [
    "### Creamos caracteristica cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878d6ae",
   "metadata": {},
   "source": [
    "### Transformacion distribucion de variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f67fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tranformation_Distribution (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    # Iteramos por el nombre de columna de X_copy, devolviendo el valor devuelto por boxcox (no el valor lambda).\n",
    "    def transform(self,X):\n",
    "        X_copy = X.copy()    \n",
    "        column_names = ['Bilirubin','Cholesterol','Copper','Alk_Phos','SGOT','Tryglicerides','Prothrombin']\n",
    "        \n",
    "        for i in column_names:\n",
    "            transformed_col,_ = stats.boxcox(X_copy[i])\n",
    "            X_copy[i] = transformed_col\n",
    "        \n",
    "        X_copy = X_copy.drop('N_Days', axis = 1)\n",
    "        \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95ac2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_ = Tranformation_Distribution()\n",
    "X = transformers_.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8343b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering (BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    # Iteramos por el nombre de columna de X_copy, devolviendo el valor devuelto por boxcox (no el valor lambda).\n",
    "    def transform(self,X):\n",
    "        X_copy = X.copy()    \n",
    "        \n",
    "        # pipeline para escalar numericos y codificar categoricos\n",
    "        numerical_columns = X_copy.select_dtypes(include='number')\n",
    "        categorical_columns = X_copy.select_dtypes(exclude='number')\n",
    "\n",
    "\n",
    "        # automatizado de transformacion categoricas y numericas (Normalizado y OneHot)\n",
    "        categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore',sparse_output=False, drop='first'))\n",
    "        numerical_pipeline = make_pipeline(MinMaxScaler())\n",
    "\n",
    "        preprocessing = ColumnTransformer([\n",
    "            ('num', numerical_pipeline, numerical_columns.columns),\n",
    "            ('cat', categorical_pipeline, categorical_columns.columns),\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "        # Unimos en un pipeline global\n",
    "        pipeline_full = make_pipeline(preprocessing)\n",
    "\n",
    "        X_processed = pipeline_full.fit_transform(X_copy)\n",
    "\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "        y_kmeans = kmeans.fit_predict(X_processed)\n",
    "        \n",
    "        \n",
    "        # transformar X_processed a series de pandas(dataframe)\n",
    "        X_copy = pd.DataFrame(X_processed, columns= preprocessing.get_feature_names_out())\n",
    "        # unimos vector de predicciones con df\n",
    "        X_copy['cluster'] = list(y_kmeans)\n",
    "        \n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8231fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering_ =  Clustering()\n",
    "X = Clustering_.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa7e889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7905 entries, 0 to 7904\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   num__Bilirubin           7905 non-null   float64\n",
      " 1   num__Cholesterol         7905 non-null   float64\n",
      " 2   num__Albumin             7905 non-null   float64\n",
      " 3   num__Copper              7905 non-null   float64\n",
      " 4   num__Alk_Phos            7905 non-null   float64\n",
      " 5   num__SGOT                7905 non-null   float64\n",
      " 6   num__Tryglicerides       7905 non-null   float64\n",
      " 7   num__Platelets           7905 non-null   float64\n",
      " 8   num__Prothrombin         7905 non-null   float64\n",
      " 9   num__Stage               7905 non-null   float64\n",
      " 10  num__Age                 7905 non-null   float64\n",
      " 11  num__Sgot_survival       7905 non-null   float64\n",
      " 12  num__Bilirubin_survival  7905 non-null   float64\n",
      " 13  num__Copper_survival     7905 non-null   float64\n",
      " 14  cat__Drug_Placebo        7905 non-null   float64\n",
      " 15  cat__Sex_M               7905 non-null   float64\n",
      " 16  cat__Ascites_Y           7905 non-null   float64\n",
      " 17  cat__Hepatomegaly_Y      7905 non-null   float64\n",
      " 18  cat__Spiders_Y           7905 non-null   float64\n",
      " 19  cat__Edema_S             7905 non-null   float64\n",
      " 20  cat__Edema_Y             7905 non-null   float64\n",
      " 21  cluster                  7905 non-null   int32  \n",
      "dtypes: float64(21), int32(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f3fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos csv con variables predictoras para realizar en otro notebook la agrupacion por cluster(buscando patrones).\n",
    "X.to_csv('clustering_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210c65d",
   "metadata": {},
   "source": [
    "### Pipeline de procesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b19ba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__Bilirubin</th>\n",
       "      <th>num__Cholesterol</th>\n",
       "      <th>num__Albumin</th>\n",
       "      <th>num__Copper</th>\n",
       "      <th>num__Alk_Phos</th>\n",
       "      <th>num__SGOT</th>\n",
       "      <th>num__Tryglicerides</th>\n",
       "      <th>num__Platelets</th>\n",
       "      <th>num__Prothrombin</th>\n",
       "      <th>num__Stage</th>\n",
       "      <th>...</th>\n",
       "      <th>num__Bilirubin_survival</th>\n",
       "      <th>num__Copper_survival</th>\n",
       "      <th>cat__Drug_Placebo</th>\n",
       "      <th>cat__Sex_M</th>\n",
       "      <th>cat__Ascites_Y</th>\n",
       "      <th>cat__Hepatomegaly_Y</th>\n",
       "      <th>cat__Spiders_Y</th>\n",
       "      <th>cat__Edema_S</th>\n",
       "      <th>cat__Edema_Y</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703920</td>\n",
       "      <td>0.611883</td>\n",
       "      <td>0.518657</td>\n",
       "      <td>0.751284</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.675003</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.662675</td>\n",
       "      <td>0.270725</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.462568</td>\n",
       "      <td>0.667585</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>0.641062</td>\n",
       "      <td>0.574429</td>\n",
       "      <td>0.431628</td>\n",
       "      <td>0.596806</td>\n",
       "      <td>0.580596</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.771384</td>\n",
       "      <td>0.588312</td>\n",
       "      <td>0.593284</td>\n",
       "      <td>0.696402</td>\n",
       "      <td>0.545185</td>\n",
       "      <td>0.531684</td>\n",
       "      <td>0.197319</td>\n",
       "      <td>0.273453</td>\n",
       "      <td>0.685430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319490</td>\n",
       "      <td>0.516217</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.532648</td>\n",
       "      <td>0.676068</td>\n",
       "      <td>0.350958</td>\n",
       "      <td>0.464528</td>\n",
       "      <td>0.413174</td>\n",
       "      <td>0.524815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.523705</td>\n",
       "      <td>0.648336</td>\n",
       "      <td>0.630597</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>0.586411</td>\n",
       "      <td>0.549417</td>\n",
       "      <td>0.464528</td>\n",
       "      <td>0.471058</td>\n",
       "      <td>0.504469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>0.423839</td>\n",
       "      <td>0.602462</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.447931</td>\n",
       "      <td>0.672468</td>\n",
       "      <td>0.387205</td>\n",
       "      <td>0.746485</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.331830</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>0.462568</td>\n",
       "      <td>0.523829</td>\n",
       "      <td>0.548507</td>\n",
       "      <td>0.546026</td>\n",
       "      <td>0.641062</td>\n",
       "      <td>0.592505</td>\n",
       "      <td>0.384677</td>\n",
       "      <td>0.429142</td>\n",
       "      <td>0.360187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>0.674492</td>\n",
       "      <td>0.449006</td>\n",
       "      <td>0.458955</td>\n",
       "      <td>0.506860</td>\n",
       "      <td>0.514139</td>\n",
       "      <td>0.343234</td>\n",
       "      <td>0.290848</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>0.791054</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>0.377195</td>\n",
       "      <td>0.500329</td>\n",
       "      <td>0.294776</td>\n",
       "      <td>0.413554</td>\n",
       "      <td>0.537216</td>\n",
       "      <td>0.274392</td>\n",
       "      <td>0.539435</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.504469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>0.377195</td>\n",
       "      <td>0.516217</td>\n",
       "      <td>0.473881</td>\n",
       "      <td>0.338708</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.365912</td>\n",
       "      <td>0.418289</td>\n",
       "      <td>0.546906</td>\n",
       "      <td>0.437452</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7905 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num__Bilirubin  num__Cholesterol  num__Albumin  num__Copper  \\\n",
       "0           0.703920          0.611883      0.518657     0.751284   \n",
       "1           0.462568          0.667585      0.589552     0.549236   \n",
       "2           0.771384          0.588312      0.593284     0.696402   \n",
       "3           0.319490          0.516217      0.574627     0.532648   \n",
       "4           0.523705          0.648336      0.630597     0.549236   \n",
       "...              ...               ...           ...          ...   \n",
       "7900        0.423839          0.602462      0.597015     0.447931   \n",
       "7901        0.462568          0.523829      0.548507     0.546026   \n",
       "7902        0.674492          0.449006      0.458955     0.506860   \n",
       "7903        0.377195          0.500329      0.294776     0.413554   \n",
       "7904        0.377195          0.516217      0.473881     0.338708   \n",
       "\n",
       "      num__Alk_Phos  num__SGOT  num__Tryglicerides  num__Platelets  \\\n",
       "0          0.668167   0.675003            0.297584        0.662675   \n",
       "1          0.641062   0.574429            0.431628        0.596806   \n",
       "2          0.545185   0.531684            0.197319        0.273453   \n",
       "3          0.676068   0.350958            0.464528        0.413174   \n",
       "4          0.586411   0.549417            0.464528        0.471058   \n",
       "...             ...        ...                 ...             ...   \n",
       "7900       0.672468   0.387205            0.746485        0.562874   \n",
       "7901       0.641062   0.592505            0.384677        0.429142   \n",
       "7902       0.514139   0.343234            0.290848        0.275449   \n",
       "7903       0.537216   0.274392            0.539435        0.317365   \n",
       "7904       0.382756   0.365912            0.418289        0.546906   \n",
       "\n",
       "      num__Prothrombin  num__Stage  ...  num__Bilirubin_survival  \\\n",
       "0             0.270725    0.666667  ...                      1.0   \n",
       "1             0.580596    0.666667  ...                      0.0   \n",
       "2             0.685430    1.000000  ...                      1.0   \n",
       "3             0.524815    0.666667  ...                      0.0   \n",
       "4             0.504469    1.000000  ...                      0.0   \n",
       "...                ...         ...  ...                      ...   \n",
       "7900          0.331830    0.333333  ...                      0.0   \n",
       "7901          0.360187    1.000000  ...                      0.0   \n",
       "7902          0.791054    0.333333  ...                      1.0   \n",
       "7903          0.504469    1.000000  ...                      0.0   \n",
       "7904          0.437452    0.666667  ...                      0.0   \n",
       "\n",
       "      num__Copper_survival  cat__Drug_Placebo  cat__Sex_M  cat__Ascites_Y  \\\n",
       "0                      1.0                0.0         1.0             0.0   \n",
       "1                      1.0                1.0         0.0             0.0   \n",
       "2                      1.0                1.0         0.0             0.0   \n",
       "3                      0.0                1.0         0.0             0.0   \n",
       "4                      1.0                1.0         0.0             0.0   \n",
       "...                    ...                ...         ...             ...   \n",
       "7900                   0.0                0.0         0.0             0.0   \n",
       "7901                   1.0                1.0         0.0             0.0   \n",
       "7902                   0.0                0.0         0.0             0.0   \n",
       "7903                   0.0                0.0         1.0             0.0   \n",
       "7904                   0.0                0.0         0.0             0.0   \n",
       "\n",
       "      cat__Hepatomegaly_Y  cat__Spiders_Y  cat__Edema_S  cat__Edema_Y  cluster  \n",
       "0                     0.0             0.0           0.0           0.0        0  \n",
       "1                     0.0             0.0           0.0           0.0        1  \n",
       "2                     1.0             1.0           0.0           1.0        0  \n",
       "3                     0.0             0.0           0.0           0.0        1  \n",
       "4                     1.0             0.0           0.0           0.0        0  \n",
       "...                   ...             ...           ...           ...      ...  \n",
       "7900                  0.0             0.0           0.0           0.0        1  \n",
       "7901                  1.0             0.0           0.0           0.0        0  \n",
       "7902                  0.0             1.0           1.0           0.0        1  \n",
       "7903                  1.0             0.0           0.0           0.0        1  \n",
       "7904                  0.0             0.0           0.0           0.0        1  \n",
       "\n",
       "[7905 rows x 22 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatizado de clases con funciones de ingenieria de variables.\n",
    "class_pipeline = make_pipeline(Age_, Sgot_, Bilirubin_, Copper_, transformers_, Clustering_)\n",
    "\n",
    "X_processed = class_pipeline.fit_transform(X)\n",
    "X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "707c8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificamos y\n",
    "scaler_y = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_y = scaler_y.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08ea9e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b5f678",
   "metadata": {},
   "source": [
    "### Prediccion con redes, Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "112fce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "198/198 [==============================] - 3s 4ms/step - loss: 1.4487 - accuracy: 0.4342 - val_loss: 0.7403 - val_accuracy: 0.7679\n",
      "Epoch 2/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 1.0313 - accuracy: 0.5995 - val_loss: 0.6359 - val_accuracy: 0.7843\n",
      "Epoch 3/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.8502 - accuracy: 0.6795 - val_loss: 0.5908 - val_accuracy: 0.7900\n",
      "Epoch 4/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.7824 - accuracy: 0.7021 - val_loss: 0.5629 - val_accuracy: 0.7868\n",
      "Epoch 5/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.7200 - accuracy: 0.7381 - val_loss: 0.5503 - val_accuracy: 0.7938\n",
      "Epoch 6/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.6786 - accuracy: 0.7434 - val_loss: 0.5387 - val_accuracy: 0.7932\n",
      "Epoch 7/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.6638 - accuracy: 0.7460 - val_loss: 0.5312 - val_accuracy: 0.7944\n",
      "Epoch 8/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.7554 - val_loss: 0.5267 - val_accuracy: 0.7976\n",
      "Epoch 9/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.7652 - val_loss: 0.5217 - val_accuracy: 0.7957\n",
      "Epoch 10/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.7671 - val_loss: 0.5184 - val_accuracy: 0.7970\n",
      "Epoch 11/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.6163 - accuracy: 0.7596 - val_loss: 0.5153 - val_accuracy: 0.8014\n",
      "Epoch 12/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5991 - accuracy: 0.7704 - val_loss: 0.5129 - val_accuracy: 0.8046\n",
      "Epoch 13/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5989 - accuracy: 0.7650 - val_loss: 0.5105 - val_accuracy: 0.8046\n",
      "Epoch 14/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5916 - accuracy: 0.7751 - val_loss: 0.5079 - val_accuracy: 0.8014\n",
      "Epoch 15/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.7690 - val_loss: 0.5072 - val_accuracy: 0.8058\n",
      "Epoch 16/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5842 - accuracy: 0.7758 - val_loss: 0.5053 - val_accuracy: 0.8065\n",
      "Epoch 17/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5862 - accuracy: 0.7764 - val_loss: 0.5054 - val_accuracy: 0.8077\n",
      "Epoch 18/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.7744 - val_loss: 0.5044 - val_accuracy: 0.8090\n",
      "Epoch 19/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5815 - accuracy: 0.7802 - val_loss: 0.5037 - val_accuracy: 0.8077\n",
      "Epoch 20/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5773 - accuracy: 0.7772 - val_loss: 0.5023 - val_accuracy: 0.8083\n",
      "Epoch 21/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.7794 - val_loss: 0.5024 - val_accuracy: 0.8077\n",
      "Epoch 22/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5743 - accuracy: 0.7800 - val_loss: 0.5019 - val_accuracy: 0.8065\n",
      "Epoch 23/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5687 - accuracy: 0.7870 - val_loss: 0.5005 - val_accuracy: 0.8102\n",
      "Epoch 24/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5652 - accuracy: 0.7861 - val_loss: 0.4977 - val_accuracy: 0.8121\n",
      "Epoch 25/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5703 - accuracy: 0.7772 - val_loss: 0.4976 - val_accuracy: 0.8102\n",
      "Epoch 26/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5643 - accuracy: 0.7837 - val_loss: 0.4979 - val_accuracy: 0.8096\n",
      "Epoch 27/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5652 - accuracy: 0.7843 - val_loss: 0.4982 - val_accuracy: 0.8128\n",
      "Epoch 28/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5623 - accuracy: 0.7837 - val_loss: 0.4966 - val_accuracy: 0.8115\n",
      "Epoch 29/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.7835 - val_loss: 0.4968 - val_accuracy: 0.8134\n",
      "Epoch 30/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5578 - accuracy: 0.7867 - val_loss: 0.4976 - val_accuracy: 0.8109\n",
      "Epoch 31/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5562 - accuracy: 0.7914 - val_loss: 0.4945 - val_accuracy: 0.8166\n",
      "Epoch 32/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5641 - accuracy: 0.7864 - val_loss: 0.4978 - val_accuracy: 0.8140\n",
      "Epoch 33/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5592 - accuracy: 0.7859 - val_loss: 0.4951 - val_accuracy: 0.8147\n",
      "Epoch 34/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5537 - accuracy: 0.7894 - val_loss: 0.4943 - val_accuracy: 0.8134\n",
      "Epoch 35/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5539 - accuracy: 0.7891 - val_loss: 0.4950 - val_accuracy: 0.8153\n",
      "Epoch 36/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5600 - accuracy: 0.7889 - val_loss: 0.4966 - val_accuracy: 0.8134\n",
      "Epoch 37/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.7903 - val_loss: 0.4964 - val_accuracy: 0.8128\n",
      "Epoch 38/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5594 - accuracy: 0.7876 - val_loss: 0.4948 - val_accuracy: 0.8109\n",
      "Epoch 39/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5555 - accuracy: 0.7868 - val_loss: 0.4940 - val_accuracy: 0.8121\n",
      "Epoch 40/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5563 - accuracy: 0.7875 - val_loss: 0.4941 - val_accuracy: 0.8134\n",
      "Epoch 41/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5562 - accuracy: 0.7906 - val_loss: 0.4953 - val_accuracy: 0.8147\n",
      "Epoch 42/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5467 - accuracy: 0.7965 - val_loss: 0.4936 - val_accuracy: 0.8128\n",
      "Epoch 43/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5437 - accuracy: 0.7911 - val_loss: 0.4910 - val_accuracy: 0.8128\n",
      "Epoch 44/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5512 - accuracy: 0.7898 - val_loss: 0.4919 - val_accuracy: 0.8147\n",
      "Epoch 45/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.8153\n",
      "Epoch 46/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5507 - accuracy: 0.7954 - val_loss: 0.4912 - val_accuracy: 0.8109\n",
      "Epoch 47/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5505 - accuracy: 0.7859 - val_loss: 0.4913 - val_accuracy: 0.8128\n",
      "Epoch 48/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5507 - accuracy: 0.7886 - val_loss: 0.4910 - val_accuracy: 0.8128\n",
      "Epoch 49/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5530 - accuracy: 0.7922 - val_loss: 0.4902 - val_accuracy: 0.8134\n",
      "Epoch 50/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5527 - accuracy: 0.7884 - val_loss: 0.4899 - val_accuracy: 0.8109\n",
      "Epoch 51/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5512 - accuracy: 0.7959 - val_loss: 0.4905 - val_accuracy: 0.8153\n",
      "Epoch 52/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5542 - accuracy: 0.7853 - val_loss: 0.4901 - val_accuracy: 0.8128\n",
      "Epoch 53/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5512 - accuracy: 0.7955 - val_loss: 0.4897 - val_accuracy: 0.8166\n",
      "Epoch 54/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5470 - accuracy: 0.7846 - val_loss: 0.4911 - val_accuracy: 0.8140\n",
      "Epoch 55/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5449 - accuracy: 0.7913 - val_loss: 0.4874 - val_accuracy: 0.8178\n",
      "Epoch 56/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5482 - accuracy: 0.7903 - val_loss: 0.4879 - val_accuracy: 0.8140\n",
      "Epoch 57/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5491 - accuracy: 0.7924 - val_loss: 0.4876 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5453 - accuracy: 0.7930 - val_loss: 0.4867 - val_accuracy: 0.8109\n",
      "Epoch 59/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5459 - accuracy: 0.7910 - val_loss: 0.4876 - val_accuracy: 0.8096\n",
      "Epoch 60/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5418 - accuracy: 0.7930 - val_loss: 0.4846 - val_accuracy: 0.8153\n",
      "Epoch 61/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5476 - accuracy: 0.7895 - val_loss: 0.4869 - val_accuracy: 0.8109\n",
      "Epoch 62/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5427 - accuracy: 0.7944 - val_loss: 0.4865 - val_accuracy: 0.8134\n",
      "Epoch 63/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5405 - accuracy: 0.7911 - val_loss: 0.4872 - val_accuracy: 0.8153\n",
      "Epoch 64/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5465 - accuracy: 0.7922 - val_loss: 0.4857 - val_accuracy: 0.8153\n",
      "Epoch 65/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5514 - accuracy: 0.7883 - val_loss: 0.4866 - val_accuracy: 0.8159\n",
      "Epoch 66/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5434 - accuracy: 0.7924 - val_loss: 0.4881 - val_accuracy: 0.8153\n",
      "Epoch 67/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5466 - accuracy: 0.7936 - val_loss: 0.4873 - val_accuracy: 0.8147\n",
      "Epoch 68/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5434 - accuracy: 0.7952 - val_loss: 0.4861 - val_accuracy: 0.8115\n",
      "Epoch 69/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5364 - accuracy: 0.8008 - val_loss: 0.4841 - val_accuracy: 0.8147\n",
      "Epoch 70/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7919 - val_loss: 0.4867 - val_accuracy: 0.8153\n",
      "Epoch 71/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5364 - accuracy: 0.7966 - val_loss: 0.4828 - val_accuracy: 0.8140\n",
      "Epoch 72/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5409 - accuracy: 0.7911 - val_loss: 0.4846 - val_accuracy: 0.8140\n",
      "Epoch 73/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5444 - accuracy: 0.7895 - val_loss: 0.4836 - val_accuracy: 0.8172\n",
      "Epoch 74/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5420 - accuracy: 0.7922 - val_loss: 0.4839 - val_accuracy: 0.8121\n",
      "Epoch 75/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5403 - accuracy: 0.7949 - val_loss: 0.4844 - val_accuracy: 0.8115\n",
      "Epoch 76/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5381 - accuracy: 0.7990 - val_loss: 0.4840 - val_accuracy: 0.8115\n",
      "Epoch 77/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5419 - accuracy: 0.7908 - val_loss: 0.4857 - val_accuracy: 0.8109\n",
      "Epoch 78/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5465 - accuracy: 0.7898 - val_loss: 0.4836 - val_accuracy: 0.8166\n",
      "Epoch 79/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5393 - accuracy: 0.7970 - val_loss: 0.4823 - val_accuracy: 0.8140\n",
      "Epoch 80/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.7929 - val_loss: 0.4841 - val_accuracy: 0.8115\n",
      "Epoch 81/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5412 - accuracy: 0.7933 - val_loss: 0.4823 - val_accuracy: 0.8096\n",
      "Epoch 82/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5459 - accuracy: 0.7880 - val_loss: 0.4836 - val_accuracy: 0.8147\n",
      "Epoch 83/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5389 - accuracy: 0.7944 - val_loss: 0.4844 - val_accuracy: 0.8115\n",
      "Epoch 84/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5413 - accuracy: 0.7884 - val_loss: 0.4829 - val_accuracy: 0.8121\n",
      "Epoch 85/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5427 - accuracy: 0.7924 - val_loss: 0.4834 - val_accuracy: 0.8172\n",
      "Epoch 86/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5416 - accuracy: 0.7985 - val_loss: 0.4822 - val_accuracy: 0.8083\n",
      "Epoch 87/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5415 - accuracy: 0.7924 - val_loss: 0.4829 - val_accuracy: 0.8134\n",
      "Epoch 88/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5471 - accuracy: 0.7922 - val_loss: 0.4862 - val_accuracy: 0.8153\n",
      "Epoch 89/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5347 - accuracy: 0.7949 - val_loss: 0.4819 - val_accuracy: 0.8121\n",
      "Epoch 90/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5392 - accuracy: 0.7924 - val_loss: 0.4816 - val_accuracy: 0.8140\n",
      "Epoch 91/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5399 - accuracy: 0.7976 - val_loss: 0.4826 - val_accuracy: 0.8128\n",
      "Epoch 92/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5419 - accuracy: 0.7914 - val_loss: 0.4839 - val_accuracy: 0.8109\n",
      "Epoch 93/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5376 - accuracy: 0.7943 - val_loss: 0.4837 - val_accuracy: 0.8147\n",
      "Epoch 94/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5422 - accuracy: 0.7875 - val_loss: 0.4843 - val_accuracy: 0.8147\n",
      "Epoch 95/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.7957 - val_loss: 0.4819 - val_accuracy: 0.8140\n",
      "Epoch 96/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5393 - accuracy: 0.7946 - val_loss: 0.4842 - val_accuracy: 0.8090\n",
      "Epoch 97/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5347 - accuracy: 0.7973 - val_loss: 0.4816 - val_accuracy: 0.8128\n",
      "Epoch 98/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5394 - accuracy: 0.7929 - val_loss: 0.4805 - val_accuracy: 0.8140\n",
      "Epoch 99/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5416 - accuracy: 0.7955 - val_loss: 0.4820 - val_accuracy: 0.8147\n",
      "Epoch 100/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5389 - accuracy: 0.7948 - val_loss: 0.4835 - val_accuracy: 0.8153\n",
      "Epoch 101/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5381 - accuracy: 0.7948 - val_loss: 0.4821 - val_accuracy: 0.8115\n",
      "Epoch 102/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5320 - accuracy: 0.7974 - val_loss: 0.4824 - val_accuracy: 0.8109\n",
      "Epoch 103/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5362 - accuracy: 0.7924 - val_loss: 0.4832 - val_accuracy: 0.8140\n",
      "Epoch 104/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5385 - accuracy: 0.7976 - val_loss: 0.4821 - val_accuracy: 0.8140\n",
      "Epoch 105/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5381 - accuracy: 0.7946 - val_loss: 0.4810 - val_accuracy: 0.8153\n",
      "Epoch 106/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5348 - accuracy: 0.7940 - val_loss: 0.4820 - val_accuracy: 0.8140\n",
      "Epoch 107/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5339 - accuracy: 0.7946 - val_loss: 0.4823 - val_accuracy: 0.8140\n",
      "Epoch 108/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5337 - accuracy: 0.7974 - val_loss: 0.4813 - val_accuracy: 0.8147\n",
      "Epoch 109/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5361 - accuracy: 0.7930 - val_loss: 0.4827 - val_accuracy: 0.8153\n",
      "Epoch 110/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5346 - accuracy: 0.7990 - val_loss: 0.4816 - val_accuracy: 0.8153\n",
      "Epoch 111/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5381 - accuracy: 0.7889 - val_loss: 0.4809 - val_accuracy: 0.8166\n",
      "Epoch 112/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5394 - accuracy: 0.7946 - val_loss: 0.4822 - val_accuracy: 0.8153\n",
      "Epoch 113/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7943 - val_loss: 0.4832 - val_accuracy: 0.8153\n",
      "Epoch 114/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5307 - accuracy: 0.7933 - val_loss: 0.4811 - val_accuracy: 0.8134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5331 - accuracy: 0.7973 - val_loss: 0.4804 - val_accuracy: 0.8153\n",
      "Epoch 116/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7929 - val_loss: 0.4820 - val_accuracy: 0.8172\n",
      "Epoch 117/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5318 - accuracy: 0.7952 - val_loss: 0.4818 - val_accuracy: 0.8172\n",
      "Epoch 118/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5422 - accuracy: 0.7905 - val_loss: 0.4808 - val_accuracy: 0.8159\n",
      "Epoch 119/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5347 - accuracy: 0.7914 - val_loss: 0.4819 - val_accuracy: 0.8153\n",
      "Epoch 120/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.7917 - val_loss: 0.4811 - val_accuracy: 0.8153\n",
      "Epoch 121/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5330 - accuracy: 0.7973 - val_loss: 0.4821 - val_accuracy: 0.8134\n",
      "Epoch 122/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7949 - val_loss: 0.4803 - val_accuracy: 0.8140\n",
      "Epoch 123/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7921 - val_loss: 0.4816 - val_accuracy: 0.8159\n",
      "Epoch 124/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5330 - accuracy: 0.7949 - val_loss: 0.4818 - val_accuracy: 0.8102\n",
      "Epoch 125/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5302 - accuracy: 0.7993 - val_loss: 0.4806 - val_accuracy: 0.8140\n",
      "Epoch 126/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5415 - accuracy: 0.7895 - val_loss: 0.4807 - val_accuracy: 0.8159\n",
      "Epoch 127/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5358 - accuracy: 0.7944 - val_loss: 0.4825 - val_accuracy: 0.8134\n",
      "Epoch 128/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5311 - accuracy: 0.7924 - val_loss: 0.4801 - val_accuracy: 0.8134\n",
      "Epoch 129/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5430 - accuracy: 0.7875 - val_loss: 0.4832 - val_accuracy: 0.8134\n",
      "Epoch 130/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7952 - val_loss: 0.4815 - val_accuracy: 0.8159\n",
      "Epoch 131/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5364 - accuracy: 0.7935 - val_loss: 0.4809 - val_accuracy: 0.8172\n",
      "Epoch 132/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5383 - accuracy: 0.7981 - val_loss: 0.4800 - val_accuracy: 0.8153\n",
      "Epoch 133/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5353 - accuracy: 0.7970 - val_loss: 0.4805 - val_accuracy: 0.8140\n",
      "Epoch 134/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5435 - accuracy: 0.7932 - val_loss: 0.4815 - val_accuracy: 0.8134\n",
      "Epoch 135/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5353 - accuracy: 0.7930 - val_loss: 0.4823 - val_accuracy: 0.8140\n",
      "Epoch 136/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5316 - accuracy: 0.7957 - val_loss: 0.4800 - val_accuracy: 0.8140\n",
      "Epoch 137/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5319 - accuracy: 0.7944 - val_loss: 0.4797 - val_accuracy: 0.8109\n",
      "Epoch 138/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7968 - val_loss: 0.4807 - val_accuracy: 0.8140\n",
      "Epoch 139/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.7938 - val_loss: 0.4803 - val_accuracy: 0.8147\n",
      "Epoch 140/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5421 - accuracy: 0.7846 - val_loss: 0.4813 - val_accuracy: 0.8134\n",
      "Epoch 141/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5292 - accuracy: 0.7938 - val_loss: 0.4789 - val_accuracy: 0.8204\n",
      "Epoch 142/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5350 - accuracy: 0.7951 - val_loss: 0.4808 - val_accuracy: 0.8185\n",
      "Epoch 143/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5343 - accuracy: 0.7936 - val_loss: 0.4783 - val_accuracy: 0.8166\n",
      "Epoch 144/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5333 - accuracy: 0.7935 - val_loss: 0.4791 - val_accuracy: 0.8153\n",
      "Epoch 145/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5336 - accuracy: 0.7949 - val_loss: 0.4817 - val_accuracy: 0.8147\n",
      "Epoch 146/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7954 - val_loss: 0.4803 - val_accuracy: 0.8109\n",
      "Epoch 147/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7952 - val_loss: 0.4797 - val_accuracy: 0.8121\n",
      "Epoch 148/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5352 - accuracy: 0.7935 - val_loss: 0.4793 - val_accuracy: 0.8147\n",
      "Epoch 149/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7935 - val_loss: 0.4801 - val_accuracy: 0.8140\n",
      "Epoch 150/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5343 - accuracy: 0.7954 - val_loss: 0.4805 - val_accuracy: 0.8140\n",
      "Epoch 151/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5293 - accuracy: 0.7938 - val_loss: 0.4787 - val_accuracy: 0.8102\n",
      "Epoch 152/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5348 - accuracy: 0.7936 - val_loss: 0.4796 - val_accuracy: 0.8147\n",
      "Epoch 153/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5343 - accuracy: 0.7935 - val_loss: 0.4789 - val_accuracy: 0.8159\n",
      "Epoch 154/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.8009 - val_loss: 0.4811 - val_accuracy: 0.8159\n",
      "Epoch 155/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7974 - val_loss: 0.4794 - val_accuracy: 0.8153\n",
      "Epoch 156/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.7943 - val_loss: 0.4814 - val_accuracy: 0.8185\n",
      "Epoch 157/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5287 - accuracy: 0.7955 - val_loss: 0.4814 - val_accuracy: 0.8140\n",
      "Epoch 158/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5263 - accuracy: 0.7959 - val_loss: 0.4801 - val_accuracy: 0.8147\n",
      "Epoch 159/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5303 - accuracy: 0.7943 - val_loss: 0.4811 - val_accuracy: 0.8121\n",
      "Epoch 160/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7971 - val_loss: 0.4809 - val_accuracy: 0.8159\n",
      "Epoch 161/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7992 - val_loss: 0.4794 - val_accuracy: 0.8153\n",
      "Epoch 162/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5319 - accuracy: 0.7946 - val_loss: 0.4791 - val_accuracy: 0.8147\n",
      "Epoch 163/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.8004 - val_loss: 0.4815 - val_accuracy: 0.8166\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarod\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5328 - accuracy: 0.7962 - val_loss: 0.4976 - val_accuracy: 0.8134\n",
      "Epoch 2/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5283 - accuracy: 0.7990 - val_loss: 0.4987 - val_accuracy: 0.8128\n",
      "Epoch 3/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7966 - val_loss: 0.5005 - val_accuracy: 0.8134\n",
      "Epoch 4/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7966 - val_loss: 0.5006 - val_accuracy: 0.8128\n",
      "Epoch 5/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5310 - accuracy: 0.7951 - val_loss: 0.4995 - val_accuracy: 0.8121\n",
      "Epoch 6/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.7933 - val_loss: 0.5011 - val_accuracy: 0.8077\n",
      "Epoch 7/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.7973 - val_loss: 0.5006 - val_accuracy: 0.8121\n",
      "Epoch 8/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.8008 - val_loss: 0.5012 - val_accuracy: 0.8102\n",
      "Epoch 9/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5245 - accuracy: 0.7997 - val_loss: 0.5014 - val_accuracy: 0.8096\n",
      "Epoch 10/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7955 - val_loss: 0.5015 - val_accuracy: 0.8109\n",
      "Epoch 11/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7960 - val_loss: 0.5014 - val_accuracy: 0.8102\n",
      "Epoch 12/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.7970 - val_loss: 0.5011 - val_accuracy: 0.8128\n",
      "Epoch 13/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7954 - val_loss: 0.5011 - val_accuracy: 0.8128\n",
      "Epoch 14/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.7985 - val_loss: 0.5015 - val_accuracy: 0.8121\n",
      "Epoch 15/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5214 - accuracy: 0.8034 - val_loss: 0.5021 - val_accuracy: 0.8083\n",
      "Epoch 16/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.7982 - val_loss: 0.5018 - val_accuracy: 0.8096\n",
      "Epoch 17/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7970 - val_loss: 0.5026 - val_accuracy: 0.8102\n",
      "Epoch 18/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.8015 - val_loss: 0.5018 - val_accuracy: 0.8147\n",
      "Epoch 19/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5269 - accuracy: 0.7998 - val_loss: 0.5032 - val_accuracy: 0.8090\n",
      "Epoch 20/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.7963 - val_loss: 0.5033 - val_accuracy: 0.8121\n",
      "Epoch 21/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.8134\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8134\n",
      "Epoch 1/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5279 - accuracy: 0.7935 - val_loss: 0.4840 - val_accuracy: 0.8147\n",
      "Epoch 2/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5329 - accuracy: 0.7948 - val_loss: 0.4850 - val_accuracy: 0.8147\n",
      "Epoch 3/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5351 - accuracy: 0.7948 - val_loss: 0.4833 - val_accuracy: 0.8159\n",
      "Epoch 4/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5371 - accuracy: 0.7941 - val_loss: 0.4830 - val_accuracy: 0.8178\n",
      "Epoch 5/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5327 - accuracy: 0.7940 - val_loss: 0.4841 - val_accuracy: 0.8159\n",
      "Epoch 6/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5361 - accuracy: 0.7898 - val_loss: 0.4860 - val_accuracy: 0.8153\n",
      "Epoch 7/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5337 - accuracy: 0.7919 - val_loss: 0.4868 - val_accuracy: 0.8128\n",
      "Epoch 8/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5293 - accuracy: 0.7976 - val_loss: 0.4868 - val_accuracy: 0.8140\n",
      "Epoch 9/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5315 - accuracy: 0.7946 - val_loss: 0.4889 - val_accuracy: 0.8147\n",
      "Epoch 10/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7933 - val_loss: 0.4880 - val_accuracy: 0.8140\n",
      "Epoch 11/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7951 - val_loss: 0.4890 - val_accuracy: 0.8140\n",
      "Epoch 12/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5278 - accuracy: 0.7976 - val_loss: 0.4889 - val_accuracy: 0.8115\n",
      "Epoch 13/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7957 - val_loss: 0.4896 - val_accuracy: 0.8134\n",
      "Epoch 14/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7948 - val_loss: 0.4876 - val_accuracy: 0.8128\n",
      "Epoch 15/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5288 - accuracy: 0.7952 - val_loss: 0.4906 - val_accuracy: 0.8115\n",
      "Epoch 16/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.7962 - val_loss: 0.4908 - val_accuracy: 0.8096\n",
      "Epoch 17/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5279 - accuracy: 0.7966 - val_loss: 0.4881 - val_accuracy: 0.8147\n",
      "Epoch 18/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7921 - val_loss: 0.4887 - val_accuracy: 0.8109\n",
      "Epoch 19/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.7976 - val_loss: 0.4876 - val_accuracy: 0.8090\n",
      "Epoch 20/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7910 - val_loss: 0.4912 - val_accuracy: 0.8090\n",
      "Epoch 21/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5320 - accuracy: 0.7949 - val_loss: 0.4896 - val_accuracy: 0.8109\n",
      "Epoch 22/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5335 - accuracy: 0.7968 - val_loss: 0.4899 - val_accuracy: 0.8096\n",
      "Epoch 23/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.7985 - val_loss: 0.4893 - val_accuracy: 0.8115\n",
      "Epoch 24/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5283 - accuracy: 0.7930 - val_loss: 0.4894 - val_accuracy: 0.8109\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8178\n",
      "Epoch 1/400\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.7946 - val_loss: 0.4865 - val_accuracy: 0.8109\n",
      "Epoch 2/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.7968 - val_loss: 0.4857 - val_accuracy: 0.8077\n",
      "Epoch 3/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7984 - val_loss: 0.4881 - val_accuracy: 0.8077\n",
      "Epoch 4/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5344 - accuracy: 0.7955 - val_loss: 0.4878 - val_accuracy: 0.8102\n",
      "Epoch 5/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5276 - accuracy: 0.8025 - val_loss: 0.4872 - val_accuracy: 0.8102\n",
      "Epoch 6/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5298 - accuracy: 0.7984 - val_loss: 0.4884 - val_accuracy: 0.8121\n",
      "Epoch 7/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7965 - val_loss: 0.4872 - val_accuracy: 0.8102\n",
      "Epoch 8/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5272 - accuracy: 0.7976 - val_loss: 0.4878 - val_accuracy: 0.8096\n",
      "Epoch 9/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5279 - accuracy: 0.7993 - val_loss: 0.4875 - val_accuracy: 0.8083\n",
      "Epoch 10/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5322 - accuracy: 0.7960 - val_loss: 0.4859 - val_accuracy: 0.8102\n",
      "Epoch 11/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7981 - val_loss: 0.4897 - val_accuracy: 0.8065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5302 - accuracy: 0.7971 - val_loss: 0.4875 - val_accuracy: 0.8065\n",
      "Epoch 13/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7974 - val_loss: 0.4890 - val_accuracy: 0.8083\n",
      "Epoch 14/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7966 - val_loss: 0.4883 - val_accuracy: 0.8083\n",
      "Epoch 15/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5246 - accuracy: 0.7989 - val_loss: 0.4885 - val_accuracy: 0.8096\n",
      "Epoch 16/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7960 - val_loss: 0.4880 - val_accuracy: 0.8090\n",
      "Epoch 17/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.7976 - val_loss: 0.4875 - val_accuracy: 0.8096\n",
      "Epoch 18/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5348 - accuracy: 0.7954 - val_loss: 0.4894 - val_accuracy: 0.8090\n",
      "Epoch 19/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5310 - accuracy: 0.8006 - val_loss: 0.4894 - val_accuracy: 0.8071\n",
      "Epoch 20/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5302 - accuracy: 0.7976 - val_loss: 0.4885 - val_accuracy: 0.8083\n",
      "Epoch 21/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.7993 - val_loss: 0.4902 - val_accuracy: 0.8058\n",
      "Epoch 22/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5287 - accuracy: 0.7985 - val_loss: 0.4894 - val_accuracy: 0.8090\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8077\n",
      "Epoch 1/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.8014 - val_loss: 0.5081 - val_accuracy: 0.8001\n",
      "Epoch 2/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5267 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7995\n",
      "Epoch 3/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.8020 - val_loss: 0.5097 - val_accuracy: 0.7989\n",
      "Epoch 4/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.8030 - val_loss: 0.5100 - val_accuracy: 0.7976\n",
      "Epoch 5/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7925 - val_loss: 0.5111 - val_accuracy: 0.7995\n",
      "Epoch 6/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8033 - val_loss: 0.5128 - val_accuracy: 0.7982\n",
      "Epoch 7/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.7948 - val_loss: 0.5122 - val_accuracy: 0.7995\n",
      "Epoch 8/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5244 - accuracy: 0.7970 - val_loss: 0.5114 - val_accuracy: 0.7989\n",
      "Epoch 9/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.7976 - val_loss: 0.5136 - val_accuracy: 0.7982\n",
      "Epoch 10/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.7990 - val_loss: 0.5135 - val_accuracy: 0.7982\n",
      "Epoch 11/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5232 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7989\n",
      "Epoch 12/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.7993 - val_loss: 0.5144 - val_accuracy: 0.7989\n",
      "Epoch 13/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.8000 - val_loss: 0.5147 - val_accuracy: 0.7970\n",
      "Epoch 14/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5265 - accuracy: 0.8008 - val_loss: 0.5161 - val_accuracy: 0.7963\n",
      "Epoch 15/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.8008 - val_loss: 0.5147 - val_accuracy: 0.7963\n",
      "Epoch 16/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.8008 - val_loss: 0.5149 - val_accuracy: 0.7982\n",
      "Epoch 17/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8020 - val_loss: 0.5154 - val_accuracy: 0.7970\n",
      "Epoch 18/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.8041 - val_loss: 0.5151 - val_accuracy: 0.7989\n",
      "Epoch 19/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5257 - accuracy: 0.8023 - val_loss: 0.5155 - val_accuracy: 0.8027\n",
      "Epoch 20/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.7965 - val_loss: 0.5158 - val_accuracy: 0.7982\n",
      "Epoch 21/400\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.7979 - val_loss: 0.5164 - val_accuracy: 0.7982\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8001\n"
     ]
    }
   ],
   "source": [
    "# Convertir los datos a matrices NumPy\n",
    "X_processed = X_processed.to_numpy()\n",
    "scores = []\n",
    "\n",
    "FOLDS = 5\n",
    "skf = IterativeStratification(n_splits=FOLDS)\n",
    "\n",
    "# Define la arquitectura del modelo fuera del bucle\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(25, activation='relu', input_dim=22),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax'),\n",
    "])\n",
    "\n",
    "optimizador = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "modelo.compile(optimizer=optimizador, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_processed, encoded_y)):\n",
    "    # Separar en conjunto de entrenamiento y validación\n",
    "    X_train, X_val = X_processed[train_index], X_processed[test_index]\n",
    "    y_train, y_val = encoded_y[train_index], encoded_y[test_index]\n",
    "\n",
    "    # Ajustar y entrenar el modelo de red neuronal\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "    filepath = './checkpoints/checkpoint'\n",
    "    best_model = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, save_best_only=True, save_weights_only=True,\n",
    "                                                    monitor='val_loss', mode='min')\n",
    "    history = modelo.fit(X_train, y_train, batch_size=32, callbacks=[early_stop, best_model], epochs=400,\n",
    "                         validation_data=(X_val, y_val))\n",
    "    modelo.load_weights(filepath)\n",
    "    modelo.save(f'model{i+1}.h5')\n",
    "    score = modelo.evaluate(X_val, y_val)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c477c",
   "metadata": {},
   "source": [
    "### Prediccion de los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "933ed9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>3839</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>19724</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>546.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>2468</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>14975</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>155.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>51</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>13149</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>46.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>101.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>2330</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>20510</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>293.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>40.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>56.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>1615</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21904</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.4</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>125.00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>13171</td>\n",
       "      <td>2870</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>12279</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.3</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>13172</td>\n",
       "      <td>1770</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>24803</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>121.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>94.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>13173</td>\n",
       "      <td>3707</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>16990</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8</td>\n",
       "      <td>315.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1637.0</td>\n",
       "      <td>170.50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>13174</td>\n",
       "      <td>1216</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>11773</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.7</td>\n",
       "      <td>329.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>52.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>13175</td>\n",
       "      <td>2272</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21600</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>170.50</td>\n",
       "      <td>83.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5271 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n",
       "0      7905    3839  D-penicillamine  19724   F       N            Y       N   \n",
       "1      7906    2468  D-penicillamine  14975   F       N            N       N   \n",
       "2      7907      51          Placebo  13149   F       N            Y       N   \n",
       "3      7908    2330  D-penicillamine  20510   F       N            N       N   \n",
       "4      7909    1615  D-penicillamine  21904   F       N            Y       N   \n",
       "...     ...     ...              ...    ...  ..     ...          ...     ...   \n",
       "5266  13171    2870          Placebo  12279   F       N            N       N   \n",
       "5267  13172    1770          Placebo  24803   F       N            N       N   \n",
       "5268  13173    3707  D-penicillamine  16990   F       N            Y       N   \n",
       "5269  13174    1216          Placebo  11773   F       N            N       N   \n",
       "5270  13175    2272  D-penicillamine  21600   F       N            N       N   \n",
       "\n",
       "     Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "0        N        1.2        546.0     3.37    65.0    1636.0  151.90   \n",
       "1        N        1.1        660.0     4.22    94.0    1257.0  151.90   \n",
       "2        Y        2.0        151.0     2.96    46.0     961.0   69.75   \n",
       "3        N        0.6        293.0     3.85    40.0     554.0  125.55   \n",
       "4        N        1.4        277.0     2.97   121.0    1110.0  125.00   \n",
       "...    ...        ...          ...      ...     ...       ...     ...   \n",
       "5266     N        1.3        302.0     3.43    75.0    1345.0  145.00   \n",
       "5267     N        0.5        219.0     4.09   121.0     663.0   79.05   \n",
       "5268     N        0.8        315.0     4.09    13.0    1637.0  170.50   \n",
       "5269     N        0.7        329.0     3.80    52.0     678.0   57.00   \n",
       "5270     N        2.0        232.0     3.42    18.0    1636.0  170.50   \n",
       "\n",
       "      Tryglicerides  Platelets  Prothrombin  Stage  \n",
       "0              90.0      430.0         10.6    2.0  \n",
       "1             155.0      227.0         10.0    2.0  \n",
       "2             101.0      213.0         13.0    4.0  \n",
       "3              56.0      270.0         10.6    2.0  \n",
       "4             126.0      221.0          9.8    1.0  \n",
       "...             ...        ...          ...    ...  \n",
       "5266           44.0      181.0         10.6    3.0  \n",
       "5267           94.0      311.0          9.7    3.0  \n",
       "5268           70.0      426.0         10.9    3.0  \n",
       "5269          126.0      306.0         10.2    1.0  \n",
       "5270           83.0      213.0         13.6    2.0  \n",
       "\n",
       "[5271 rows x 19 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba = pd.read_csv('test.csv')\n",
    "X_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c733afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = X_prueba['id']\n",
    "X_prueba = X_prueba.drop('id', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b14d230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__Bilirubin</th>\n",
       "      <th>num__Cholesterol</th>\n",
       "      <th>num__Albumin</th>\n",
       "      <th>num__Copper</th>\n",
       "      <th>num__Alk_Phos</th>\n",
       "      <th>num__SGOT</th>\n",
       "      <th>num__Tryglicerides</th>\n",
       "      <th>num__Platelets</th>\n",
       "      <th>num__Prothrombin</th>\n",
       "      <th>num__Stage</th>\n",
       "      <th>...</th>\n",
       "      <th>num__Bilirubin_survival</th>\n",
       "      <th>num__Copper_survival</th>\n",
       "      <th>cat__Drug_Placebo</th>\n",
       "      <th>cat__Sex_M</th>\n",
       "      <th>cat__Ascites_Y</th>\n",
       "      <th>cat__Hepatomegaly_Y</th>\n",
       "      <th>cat__Spiders_Y</th>\n",
       "      <th>cat__Edema_S</th>\n",
       "      <th>cat__Edema_Y</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548898</td>\n",
       "      <td>0.802130</td>\n",
       "      <td>0.526119</td>\n",
       "      <td>0.563208</td>\n",
       "      <td>0.690757</td>\n",
       "      <td>0.617593</td>\n",
       "      <td>0.429352</td>\n",
       "      <td>0.734531</td>\n",
       "      <td>0.533102</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524165</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.636867</td>\n",
       "      <td>0.622180</td>\n",
       "      <td>0.617593</td>\n",
       "      <td>0.621233</td>\n",
       "      <td>0.329341</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674940</td>\n",
       "      <td>0.194980</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.493991</td>\n",
       "      <td>0.541666</td>\n",
       "      <td>0.344679</td>\n",
       "      <td>0.472231</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.869938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319848</td>\n",
       "      <td>0.587029</td>\n",
       "      <td>0.705224</td>\n",
       "      <td>0.465961</td>\n",
       "      <td>0.335660</td>\n",
       "      <td>0.551006</td>\n",
       "      <td>0.239510</td>\n",
       "      <td>0.415170</td>\n",
       "      <td>0.533102</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590251</td>\n",
       "      <td>0.561563</td>\n",
       "      <td>0.376866</td>\n",
       "      <td>0.687168</td>\n",
       "      <td>0.586317</td>\n",
       "      <td>0.549469</td>\n",
       "      <td>0.551134</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.317735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>0.570754</td>\n",
       "      <td>0.600263</td>\n",
       "      <td>0.548507</td>\n",
       "      <td>0.591804</td>\n",
       "      <td>0.640718</td>\n",
       "      <td>0.601358</td>\n",
       "      <td>0.134156</td>\n",
       "      <td>0.237525</td>\n",
       "      <td>0.533102</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>0.245778</td>\n",
       "      <td>0.441087</td>\n",
       "      <td>0.794776</td>\n",
       "      <td>0.687168</td>\n",
       "      <td>0.409579</td>\n",
       "      <td>0.388727</td>\n",
       "      <td>0.445665</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>0.284614</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>0.424264</td>\n",
       "      <td>0.618151</td>\n",
       "      <td>0.794776</td>\n",
       "      <td>0.239503</td>\n",
       "      <td>0.690905</td>\n",
       "      <td>0.657897</td>\n",
       "      <td>0.331565</td>\n",
       "      <td>0.726547</td>\n",
       "      <td>0.595664</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>0.377594</td>\n",
       "      <td>0.635960</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.518555</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.273509</td>\n",
       "      <td>0.551134</td>\n",
       "      <td>0.487026</td>\n",
       "      <td>0.435419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>0.674940</td>\n",
       "      <td>0.472877</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.305264</td>\n",
       "      <td>0.690757</td>\n",
       "      <td>0.657897</td>\n",
       "      <td>0.398506</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5271 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num__Bilirubin  num__Cholesterol  num__Albumin  num__Copper  \\\n",
       "0           0.548898          0.802130      0.526119     0.563208   \n",
       "1           0.524165          0.848367      0.843284     0.636867   \n",
       "2           0.674940          0.194980      0.373134     0.493991   \n",
       "3           0.319848          0.587029      0.705224     0.465961   \n",
       "4           0.590251          0.561563      0.376866     0.687168   \n",
       "...              ...               ...           ...          ...   \n",
       "5266        0.570754          0.600263      0.548507     0.591804   \n",
       "5267        0.245778          0.441087      0.794776     0.687168   \n",
       "5268        0.424264          0.618151      0.794776     0.239503   \n",
       "5269        0.377594          0.635960      0.686567     0.518555   \n",
       "5270        0.674940          0.472877      0.544776     0.305264   \n",
       "\n",
       "      num__Alk_Phos  num__SGOT  num__Tryglicerides  num__Platelets  \\\n",
       "0          0.690757   0.617593            0.429352        0.734531   \n",
       "1          0.622180   0.617593            0.621233        0.329341   \n",
       "2          0.541666   0.344679            0.472231        0.301397   \n",
       "3          0.335660   0.551006            0.239510        0.415170   \n",
       "4          0.586317   0.549469            0.551134        0.317365   \n",
       "...             ...        ...                 ...             ...   \n",
       "5266       0.640718   0.601358            0.134156        0.237525   \n",
       "5267       0.409579   0.388727            0.445665        0.497006   \n",
       "5268       0.690905   0.657897            0.331565        0.726547   \n",
       "5269       0.418301   0.273509            0.551134        0.487026   \n",
       "5270       0.690757   0.657897            0.398506        0.301397   \n",
       "\n",
       "      num__Prothrombin  num__Stage  ...  num__Bilirubin_survival  \\\n",
       "0             0.533102    0.333333  ...                      0.0   \n",
       "1             0.379368    0.333333  ...                      0.0   \n",
       "2             0.869938    1.000000  ...                      1.0   \n",
       "3             0.533102    0.333333  ...                      0.0   \n",
       "4             0.317735    0.000000  ...                      0.0   \n",
       "...                ...         ...  ...                      ...   \n",
       "5266          0.533102    0.666667  ...                      0.0   \n",
       "5267          0.284614    0.666667  ...                      0.0   \n",
       "5268          0.595664    0.666667  ...                      0.0   \n",
       "5269          0.435419    0.000000  ...                      0.0   \n",
       "5270          0.915567    0.333333  ...                      1.0   \n",
       "\n",
       "      num__Copper_survival  cat__Drug_Placebo  cat__Sex_M  cat__Ascites_Y  \\\n",
       "0                      1.0                0.0         0.0             0.0   \n",
       "1                      1.0                0.0         0.0             0.0   \n",
       "2                      0.0                1.0         0.0             0.0   \n",
       "3                      0.0                0.0         0.0             0.0   \n",
       "4                      1.0                0.0         0.0             0.0   \n",
       "...                    ...                ...         ...             ...   \n",
       "5266                   1.0                1.0         0.0             0.0   \n",
       "5267                   1.0                1.0         0.0             0.0   \n",
       "5268                   0.0                0.0         0.0             0.0   \n",
       "5269                   0.0                1.0         0.0             0.0   \n",
       "5270                   0.0                0.0         0.0             0.0   \n",
       "\n",
       "      cat__Hepatomegaly_Y  cat__Spiders_Y  cat__Edema_S  cat__Edema_Y  cluster  \n",
       "0                     1.0             0.0           0.0           0.0        0  \n",
       "1                     0.0             0.0           0.0           0.0        1  \n",
       "2                     1.0             0.0           0.0           1.0        0  \n",
       "3                     0.0             0.0           0.0           0.0        1  \n",
       "4                     1.0             0.0           0.0           0.0        0  \n",
       "...                   ...             ...           ...           ...      ...  \n",
       "5266                  0.0             0.0           0.0           0.0        1  \n",
       "5267                  0.0             0.0           0.0           0.0        1  \n",
       "5268                  1.0             0.0           0.0           0.0        1  \n",
       "5269                  0.0             0.0           0.0           0.0        1  \n",
       "5270                  0.0             0.0           0.0           0.0        1  \n",
       "\n",
       "[5271 rows x 22 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procesamos con pipeline los datos nuevos\n",
    "X_prueba = class_pipeline.fit_transform(X_prueba)\n",
    "X_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec401d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5271, 22)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfa8fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1\n",
      "165/165 [==============================] - 0s 1ms/step\n",
      "Fold2\n",
      "165/165 [==============================] - 0s 2ms/step\n",
      "Fold3\n",
      "165/165 [==============================] - 0s 1ms/step\n",
      "Fold4\n",
      "165/165 [==============================] - 0s 2ms/step\n",
      "Fold5\n",
      "165/165 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predecimos con nuestros modelos ya entrenado\n",
    "preds_= []\n",
    "for i in range(1, FOLDS+1):\n",
    "    print(f'Fold{i}')\n",
    "    model_fold = load_model(f'model{i}.h5')\n",
    "    probas = model_fold.predict(X_prueba)\n",
    "    preds_.append(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "485b4dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69986314, 0.02534635, 0.27479053],\n",
       "       [0.84966356, 0.05987134, 0.09046517],\n",
       "       [0.05200012, 0.01333658, 0.9346633 ],\n",
       "       ...,\n",
       "       [0.84398365, 0.03103164, 0.12498473],\n",
       "       [0.95308304, 0.01394567, 0.03297127],\n",
       "       [0.27706164, 0.03465195, 0.6882864 ]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Media de nuestros modelos (por folds)\n",
    "preds_mean_prueba = np.mean(preds_, axis = 0)\n",
    "preds_mean_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bd2a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en listas cada etiqueta con la probabilidad\n",
    "Status_C = []\n",
    "Status_CL = []\n",
    "Status_D = []\n",
    "for i in range(len(preds_mean_prueba)):\n",
    "    Status_C.append(preds_mean_prueba[i, 0])\n",
    "    Status_CL.append(preds_mean_prueba[i, 1])\n",
    "    Status_D.append(preds_mean_prueba[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "678e018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la submission\n",
    "submission_test = {'id': id_, 'Status_C':Status_C, 'Status_CL':Status_CL,'Status_D':Status_D}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3e64a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Status_C</th>\n",
       "      <th>Status_CL</th>\n",
       "      <th>Status_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>0.699863</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.274791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>0.849664</td>\n",
       "      <td>0.059871</td>\n",
       "      <td>0.090465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>0.934663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>0.931669</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.060252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>0.706233</td>\n",
       "      <td>0.015465</td>\n",
       "      <td>0.278302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>13171</td>\n",
       "      <td>0.800708</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.122791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>13172</td>\n",
       "      <td>0.926864</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.069621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>13173</td>\n",
       "      <td>0.843984</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>0.124985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>13174</td>\n",
       "      <td>0.953083</td>\n",
       "      <td>0.013946</td>\n",
       "      <td>0.032971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>13175</td>\n",
       "      <td>0.277062</td>\n",
       "      <td>0.034652</td>\n",
       "      <td>0.688286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Status_C  Status_CL  Status_D\n",
       "0      7905  0.699863   0.025346  0.274791\n",
       "1      7906  0.849664   0.059871  0.090465\n",
       "2      7907  0.052000   0.013337  0.934663\n",
       "3      7908  0.931669   0.008079  0.060252\n",
       "4      7909  0.706233   0.015465  0.278302\n",
       "...     ...       ...        ...       ...\n",
       "5266  13171  0.800708   0.076500  0.122791\n",
       "5267  13172  0.926864   0.003515  0.069621\n",
       "5268  13173  0.843984   0.031032  0.124985\n",
       "5269  13174  0.953083   0.013946  0.032971\n",
       "5270  13175  0.277062   0.034652  0.688286\n",
       "\n",
       "[5271 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(submission_test)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dfe195f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos\n",
    "data.to_csv('prediction_V3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
